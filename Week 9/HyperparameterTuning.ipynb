{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42d5431",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "In de reeds besproken machine learning technieken hebben we reeds een aantal keer vermeld dat er hyperparameters (denk aan regularisatieparameters, manieren van regularisatie, kernel type, ...).\n",
    "\n",
    "In het geval van lineaire regressie gaat het dan over:\n",
    "* L1 of L2 norm\n",
    "* Regularisatieparameter $\\lambda$\n",
    "* learning rate\n",
    "\n",
    "In het geval van SVM over:\n",
    "* Type kernel\n",
    "* Regularisatieparameter C\n",
    "* Regularisatieparameter $\\gamma$\n",
    "\n",
    "Tot nu bestond de zoektocht naar de optimale combinatie van deze parameters door het manueel uitproberen en evalueren van een reeks combinaties van parameters.\n",
    "Deze methode is echter niet schaalbaar en kan geautomatiseerd worden.\n",
    "Dit gebeurd door middel van een gridsearch.\n",
    "\n",
    "## Gridsearch\n",
    "\n",
    "Het gridsearch algoritme bestaat eruit om een lijst op te stellen voor elke parameter welke waarden moeten getest worden.\n",
    "Voor elke mogelijke combinatie van parameters gaat er dan een model getrained en geevalueerd worden.\n",
    "Een voorbeeld van hoe dit kan geautomatiseerd worden binnen sklearn kan [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) gevonden worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e64fc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.31 s\n",
      "Wall time: 1.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9933333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "parameters = {\n",
    "    'kernel' : ['linear', 'rbf'],\n",
    "    'C' : np.arange(1,10),\n",
    "    'gamma': np.arange(0.1, 2, 0.1)\n",
    "}\n",
    "\n",
    "svc = svm.SVC()\n",
    "gridsearch_svc = GridSearchCV(svc, param_grid=parameters)\n",
    "\n",
    "#%time svc.fit(iris.data, iris.target)\n",
    "%time gridsearch_svc.fit(iris.data, iris.target)\n",
    "\n",
    "gridsearch_svc.score(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c2f9144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2, 'gamma': 0.2, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heel wat informatie over veschillende uitgevoerde runs (scores en train times)\n",
    "gridsearch_svc.cv_results_\n",
    "\n",
    "# beste opvragen (niet nodig, je kan rechtstreeks het gridsearch model gebruiken)\n",
    "best_svc = gridsearch_svc.best_estimator_\n",
    "best_svc.score(iris.data, iris.target)\n",
    "\n",
    "gridsearch_svc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3488e5",
   "metadata": {},
   "source": [
    "De standaard methode van hierboven gaat alle combinaties afgaan.\n",
    "Andere methoden die sneller maar niet alle combinaties aftoetsen zijn\n",
    "* [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)\n",
    "* [HalvingGridSearchCv](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV)\n",
    "* [HalvingRandomizedSearchCv](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV)\n",
    "\n",
    "Belangrijk om hierbij op te merken is dat het GridSearch algoritme enkel verschillende parameters van het model trained en dat er geen eigenschappen van de data kan veranderd worden.\n",
    "Indien je ook een exhausieve search wilt doen van het aantal hogere orde features of de vorm van scaling die gebruikt wordt op input parameters. Moet je een eigen wrapper schrijven die nog deze zaken uittest en de performantie van de uiteindelijke modellen vergelijkt.\n",
    "\n",
    "## Validatieset\n",
    "\n",
    "Welke data kunnen we nu gebruiken om deze gridsearch te evalueren.\n",
    "Zowel de testdata als de trainingsdata kan niet gebruikt worden omdat we niet kunnen evalueren op de data waarmee het model getrained is.\n",
    "Om deze reden wordt de dataset typisch in drie opgedeeld, namelijk een training-, test- en validatieset.\n",
    "De validatieset is de data die dan gebruikt kan worden voor hyperparameter tuning.\n",
    "Typisch wordt de dataset dan in de volgende groottes opgedeeld:\n",
    "\n",
    "* Testset: 15%\n",
    "* Validatieset: 15% \n",
    "* Trainingsdata: 70%\n",
    "\n",
    "Dit zijn echter geen vaste waarden en kunnen wat verschillen in de praktijk.\n",
    "Hoe meer data je beschibaar is hoe groter het percentage trainingsdata kan zijn. \n",
    "In het geval van big-data applicaties kan dit oplopen tot 98%.\n",
    "\n",
    "## K-fold cross validation\n",
    "\n",
    "Bij het steeds gebruiken van dezelfde validatieset is het mogelijk dat er een unieke split is die leidt tot een onverwacht goed of slecht resultaat.\n",
    "Om dit tegen te gaan kan er gebruik gemaakt worden van K-fold cross validation.\n",
    "Daarbij berekenen we de verwachte error K keer, elke keer met een andere train en validatie set om zo de kans te verhogen dat het uiteindelijke model ook goed werkt op de testset met ongeziene data.\n",
    "Standaard wordt er bij het gebruik van het gridsearch algoritme gebruik gemaakt van 5 folds voor het zoeken naar de beste hyperparameters.\n",
    "Indien de standaard manier niet voldoet voor de gewenste toepassing kan je ook de split rechtstreeks uitvoeren.\n",
    "Meer informatie over deze methode vind je [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "\n",
    "![kfold cross validation](images/kFold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfb555",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "In [deze dataset](https://www.kaggle.com/mathchi/diabetes-data-set) is een hele reeks data beschikbaar over een aantal medische eigenschappen van personen en of deze personen diabetes hebben of niet.\n",
    "Ga nu op zoek naar het beste model om te voorspellen of een persoon diabetes gaat hebben of niet.\n",
    "Test hierbij zowel de logistische regressie en svm methoden en maak gebruik van gridsearch met 10-fold cross validation om de verschillende hyperparameters te testen. \n",
    "\n",
    "Wat is de hoogst behaalde accuraatheid en de benodigde hyperparameters?\n",
    "\n",
    "Indien dit gelukt is, zoek ook het model dat de hoogste weighted f1-score behaald. \n",
    "Welke techniek gebruikte dit model en welke hyperparameters zijn er hiervoor gekozen?\n",
    "Vergelijk beide modellen. Is er een significant verschil in de resulterende hyperparameters?\n",
    "Is de behaalde accuraatheid sterk afwijkend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebda46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fb6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading diabetes-data-set.zip to .\\diabetes-data-set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.91k/8.91k [00:00<00:00, 9.13MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/mathchi/diabetes-data-set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca31b9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.94 s\n",
      "Wall time: 9.95 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7597402597402597"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./diabetes-data-set/diabetes.csv\")\n",
    "display(df.head())\n",
    "y = df.Outcome\n",
    "X = df.drop(\"Outcome\", axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test) # --> hier enkel transform gebruiken om data leakage te voorkomen\n",
    "\n",
    "svc = SVC()\n",
    "parameters = [\n",
    "    {'kernel': ['linear'], 'C' : np.arange(1,10)},\n",
    "    {'kernel': ['poly'], 'C' : np.arange(1,10), 'degree': np.arange(1,4)},\n",
    "    {'kernel': ['rbf'], 'C' : np.arange(1,10), 'gamma': np.arange(0.1,2,0.1)}\n",
    "]\n",
    "\n",
    "gridsearch_svc = GridSearchCV(svc, parameters)\n",
    "%time gridsearch_svc.fit(X_train, y_train)\n",
    "\n",
    "gridsearch_svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09239695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3680c555",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Bij het werken met een gridsearch is er nog een probleem omtrent data leakage.\n",
    "Omdat we in bovenstaande voorbeeld de scaling hebben gedaan op de volledige dataset is alle data in principe gebruikt om de scaling uit te voeren en dus gaat er steeds een effect zijn van de training-folds op de validation-fold wat niet gewenst is.\n",
    "Dit kan onterecht de score verbeteren.\n",
    "\n",
    "Om dit tegen te gaan kan men gebruik maken van Pipelines. Hiermee definieer je de flow die de data moet ondergaan om verwerkt te worden. De volledige pipeline of flow kan dan gegeven worden aan de gridsearch algoritme. Hierdoor worden de preprocessing stappen (zoals scalers, ordinal of one-hotencoder) steeds enkel op de training folds uitgevoerd.\n",
    "Dit zorgt ervoor dat er geen data leakage kan optreden. \n",
    "Het bijkomende voordeel is dat ook parameters van de preprocessing stappen meegenomen kunnen worden in de gridsearch.\n",
    "\n",
    "Let op dat NaN waarden invullen kan gebeuren in de pipeline maar rijen of kolommen weglaten kan niet gedaan worden tijdens de pipeline. Echter is het gebruik van een pipeline een goede stap in het verhogen van de leesbaarheid van een code stuk en wordt het daardoor veelvuldig gebruikt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42d7ac38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zabour, Miss. Hileni</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>328.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zabour, Miss. Thamine</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zakarian, Mr. Mapriededer</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2656</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>304.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zakarian, Mr. Ortin</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2670</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315082</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass                                             name     sex  \\\n",
       "0        1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "1        1.0                   Allison, Master. Hudson Trevor    male   \n",
       "2        1.0                     Allison, Miss. Helen Loraine  female   \n",
       "3        1.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4        1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "...      ...                                              ...     ...   \n",
       "1304     3.0                             Zabour, Miss. Hileni  female   \n",
       "1305     3.0                            Zabour, Miss. Thamine  female   \n",
       "1306     3.0                        Zakarian, Mr. Mapriededer    male   \n",
       "1307     3.0                              Zakarian, Mr. Ortin    male   \n",
       "1308     3.0                               Zimmerman, Mr. Leo    male   \n",
       "\n",
       "          age  sibsp  parch  ticket      fare    cabin embarked  boat   body  \\\n",
       "0     29.0000    0.0    0.0   24160  211.3375       B5        S     2    NaN   \n",
       "1      0.9167    1.0    2.0  113781  151.5500  C22 C26        S    11    NaN   \n",
       "2      2.0000    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "3     30.0000    1.0    2.0  113781  151.5500  C22 C26        S  None  135.0   \n",
       "4     25.0000    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "...       ...    ...    ...     ...       ...      ...      ...   ...    ...   \n",
       "1304  14.5000    1.0    0.0    2665   14.4542     None        C  None  328.0   \n",
       "1305      NaN    1.0    0.0    2665   14.4542     None        C  None    NaN   \n",
       "1306  26.5000    0.0    0.0    2656    7.2250     None        C  None  304.0   \n",
       "1307  27.0000    0.0    0.0    2670    7.2250     None        C  None    NaN   \n",
       "1308  29.0000    0.0    0.0  315082    7.8750     None        S  None    NaN   \n",
       "\n",
       "                            home.dest  \n",
       "0                        St Louis, MO  \n",
       "1     Montreal, PQ / Chesterville, ON  \n",
       "2     Montreal, PQ / Chesterville, ON  \n",
       "3     Montreal, PQ / Chesterville, ON  \n",
       "4     Montreal, PQ / Chesterville, ON  \n",
       "...                               ...  \n",
       "1304                             None  \n",
       "1305                             None  \n",
       "1306                             None  \n",
       "1307                             None  \n",
       "1308                             None  \n",
       "\n",
       "[1309 rows x 13 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f66da894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "numeric_features = [\"age\", \"fare\"]\n",
    "categoric_features = [\"sex\", 'pclass', \"embarked\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy=\"mean\")),    # steeds naam en object\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categoric_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# anders behandelen van numerieke en categorieke data\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),                 # naam - object dat het moet uitvoeren - lijst met kolommen waarop het moet uitgevoerd worden\n",
    "    (\"cat\", categoric_transformer, categoric_features)\n",
    "])          # remainder parameter -> default drop (laat kolommen niet gespecifieerd wegvallen)\n",
    "\n",
    "# ML gedeelte\n",
    "classifier = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "#classifier.fit(X_train, y_train)\n",
    "#classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d97af998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 33 s\n",
      "Wall time: 33 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8320610687022901"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [\n",
    "    {'preprocessor__num__imputer__strategy': [\"median\", \"mean\"], 'clf__kernel': ['linear'], 'clf__C' : np.arange(1,10)},\n",
    "    {'clf__kernel': ['poly'], 'clf__C' : np.arange(1,10), 'clf__degree': np.arange(1,4)},\n",
    "    {'clf__kernel': ['rbf'], 'clf__C' : np.arange(1,10), 'clf__gamma': np.arange(0.1,2,0.1)}\n",
    "]     \n",
    "# met pipelines kan je hier speciifieren welke parameters van welke componenten in de pipeline aangepast moeten worden.\n",
    "# met dubbele underscores __ kan je een niveau afdalen\n",
    "# in de parameter grid worden altijd lijstjes verwacht (itereerbaar) en geen enkele waarden\n",
    "\n",
    "grid = GridSearchCV(classifier, parameters)\n",
    "%time grid.fit(X_train, y_train)\n",
    "\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1af1d",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "Maak een pipeline voor een gridsearch uit te voeren op de diabetes-dataset in sklearn. Gebruik een Min-Max scaler voor de numerieke waarden en een ordinal encoder voor de categorieke kolommen.\n",
    "Zoek naar de beste combinatie van hyperparameters van een SVM-classifier door middel van een grid search met cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66e916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
