{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42d5431",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "In de reeds besproken machine learning technieken hebben we reeds een aantal keer vermeld dat er hyperparameters (denk aan regularisatieparameters, manieren van regularisatie, kernel type, ...).\n",
    "\n",
    "In het geval van lineaire regressie gaat het dan over:\n",
    "* L1 of L2 norm\n",
    "* Regularisatieparameter $\\lambda$\n",
    "* learning rate\n",
    "\n",
    "In het geval van SVM over:\n",
    "* Type kernel\n",
    "* Regularisatieparameter C\n",
    "* Regularisatieparameter $\\gamma$\n",
    "\n",
    "Tot nu bestond de zoektocht naar de optimale combinatie van deze parameters door het manueel uitproberen en evalueren van een reeks combinaties van parameters.\n",
    "Deze methode is echter niet schaalbaar en kan geautomatiseerd worden.\n",
    "Dit gebeurd door middel van een gridsearch.\n",
    "\n",
    "## Gridsearch\n",
    "\n",
    "Het gridsearch algoritme bestaat eruit om een lijst op te stellen voor elke parameter welke waarden moeten getest worden.\n",
    "Voor elke mogelijke combinatie van parameters gaat er dan een model getrained en geevalueerd worden.\n",
    "Een voorbeeld van hoe dit kan geautomatiseerd worden binnen sklearn kan [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) gevonden worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3488e5",
   "metadata": {},
   "source": [
    "De standaard methode van hierboven gaat alle combinaties afgaan.\n",
    "Andere methoden die sneller maar niet alle combinaties aftoetsen zijn\n",
    "* [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)\n",
    "*[HalvingGridSearchCv](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV)\n",
    "*[HalvingRandomizedSearchCv](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV)\n",
    "\n",
    "Belangrijk om hierbij op te merken is dat het GridSearch algoritme enkel verschillende parameters van het model trained en dat er geen eigenschappen van de data kan veranderd worden.\n",
    "Indien je ook een exhausieve search wilt doen van het aantal hogere orde features of de vorm van scaling die gebruikt wordt op input parameters. Moet je een eigen wrapper schrijven die nog deze zaken uittest en de performantie van de uiteindelijke modellen vergelijkt.\n",
    "\n",
    "## Validatieset\n",
    "\n",
    "Welke data kunnen we nu gebruiken om deze gridsearch te evalueren.\n",
    "Zowel de testdata als de trainingsdata kan niet gebruikt worden omdat we niet kunnen evalueren op de data waarmee het model getrained is.\n",
    "Om deze reden wordt de dataset typisch in drie opgedeeld, namelijk een training-, test- en validatieset.\n",
    "De validatieset is de data die dan gebruikt kan worden voor hyperparameter tuning.\n",
    "Typisch wordt de dataset dan in de volgende groottes opgedeeld:\n",
    "* Testset: 15%\n",
    "* Validatieset: 15% \n",
    "* Trainingsdata: 70%\n",
    "\n",
    "Dit zijn echter geen vaste waarden en kunnen wat verschillen in de praktijk.\n",
    "Hoe meer data je beschibaar is hoe groter het percentage trainingsdata kan zijn. \n",
    "In het geval van big-data applicaties kan dit oplopen tot 98%.\n",
    "\n",
    "## K-fold cross validation\n",
    "\n",
    "Bij het steeds gebruiken van dezelfde validatieset is het mogelijk dat er een unieke split is die leidt tot een onverwacht goed of slecht resultaat.\n",
    "Om dit tegen te gaan kan er gebruik gemaakt worden van K-fold cross validation.\n",
    "Daarbij berekenen we de verwachte error K keer, elke keer met een andere train en validatie set om zo de kans te verhogen dat het uiteindelijke model ook goed werkt op de testset met ongeziene data.\n",
    "Standaard wordt er bij het gebruik van het gridsearch algoritme gebruik gemaakt van 5 folds voor het zoeken naar de beste hyperparameters.\n",
    "Indien de standaard manier niet voldoet voor de gewenste toepassing kan je ook de split rechtstreeks uitvoeren.\n",
    "Meer informatie over deze methode vind je [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "\n",
    "![kfold cross validation](images/kFold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfb555",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "In [deze dataset](https://www.kaggle.com/mathchi/diabetes-data-set) is een hele reeks data beschikbaar over een aantal medische eigenschappen van personen en of deze personen diabetes hebben of niet.\n",
    "Ga nu op zoek naar het beste model om te voorspellen of een persoon diabetes gaat hebben of niet.\n",
    "Test hierbij zowel de logistische regressie en svm methoden en maak gebruik van gridsearch met 10-fold cross validation om de verschillende hyperparameters te testen. \n",
    "\n",
    "Wat is de hoogst behaalde accuraatheid en de benodigde hyperparameters?\n",
    "\n",
    "Indien dit gelukt is, zoek ook het model dat de hoogste weighted f1-score behaald. \n",
    "Welke techniek gebruikte dit model en welke hyperparameters zijn er hiervoor gekozen?\n",
    "Vergelijk beide modellen. Is er een significant verschil in de resulterende hyperparameters?\n",
    "Is de behaalde accuraatheid sterk afwijkend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#od.download(\"https://www.kaggle.com/mathchi/diabetes-data-set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31b9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./diabetes-data-set/diabetes.csv\")\n",
    "display(df.head())\n",
    "y = df.Outcome\n",
    "X = df.drop(\"Outcome\", axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09239695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3680c555",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Bij het werken met een gridsearch is er nog een probleem omtrent data leakage.\n",
    "Omdat we in bovenstaande voorbeeld de scaling hebben gedaan op de volledige dataset is alle data in principe gebruikt om de scaling uit te voeren en dus gaat er steeds een effect zijn van de training-folds op de validation-fold wat niet gewenst is.\n",
    "Dit kan onterecht de score verbeteren.\n",
    "\n",
    "Om dit tegen te gaan kan men gebruik maken van Pipelines. Hiermee definieer je de flow die de data moet ondergaan om verwerkt te worden. De volledige pipeline of flow kan dan gegeven worden aan de gridsearch algoritme. Hierdoor worden de preprocessing stappen (zoals scalers, ordinal of one-hotencoder) steeds enkel op de training folds uitgevoerd.\n",
    "Dit zorgt ervoor dat er geen data leakage kan optreden. \n",
    "Het bijkomende voordeel is dat ook parameters van de preprocessing stappen meegenomen kunnen worden in de gridsearch.\n",
    "\n",
    "Let op dat NaN waarden invullen kan gebeuren in de pipeline maar rijen of kolommen weglaten kan niet gedaan worden tijdens de pipeline. Echter is het gebruik van een pipeline een goede stap in het verhogen van de leesbaarheid van een code stuk en wordt het daardoor veelvuldig gebruikt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66da894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97af998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2d1af1d",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "Maak een pipeline voor een gridsearch uit te voeren op de diabetes-dataset in sklearn. Gebruik een Min-Max scaler voor de numerieke waarden en een ordinal encoder voor de categorieke kolommen.\n",
    "Zoek naar de beste combinatie van hyperparameters van een SVM-classifier door middel van een grid search met cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66e916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
